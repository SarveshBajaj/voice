mysp=__import__("my-voice-analysis")
import soundfile as sf
import pyloudnorm as pyln
from threading import Thread
import math
from pydub import AudioSegment
import os, time
import speech_recognition as sr
from google.cloud import speech_v1p1beta1
from google.cloud.speech_v1p1beta1 import enums
from google.oauth2 import service_account
from google.cloud import storage
from config import *
import random

credentialsPathSpeech = 'bigTalkVoice-8f1a88e93d49.json'
credentialsPathStorage = 'bigTalkVoice-a7fdfac75e5d.json'

sliceTime = 30
fillerWords = ["um", "uh", "er", "ah", "like", "okay", "right","you know"]

def getClarityMessage(clarity):
    clarity = float(clarity)
    if(clarity >= CLARITY_RANGE[0] and clarity <= CLARITY_RANGE[1]):
        return random.choice(messages["clarity"]["good"]), True
    else:
        return random.choice(messages["clarity"]["bad"]), False

def getIntonationMessage(intonation):
    intonation = float(intonation)
    if(intonation >= INTONATION_RANGE[0] and intonation <= INTONATION_RANGE[1]):
        return random.choice(messages["intonation"]["good"]), True
    else:
        return random.choice(messages["intonation"]["bad"]), False

def getLoudnessMessage(loudness):
    loudness = float(loudness)
    if(loudness >= MINIMUM_LOUDNESS):
        return random.choice(messages["loudness"]["good"]), True
    else:
        return random.choice(messages["loudness"]["bad"]), False

def getFillerWordsMessage(numberOfFillerWords, minutes):
    if(numberOfFillerWords <= numberOfFillerWords*minutes):
        return random.choice(messages["fillerWords"]["good"]), True
    else:
        return random.choice(messages["fillerWords"]["bad"]), False

def getPausesMessage(numberOfPauses, minutes):
    numberOfPauses = float(numberOfPauses)
    if(numberOfPauses <= numberOfPauses*minutes):
        return random.choice(messages["pauses"]["good"]), True
    else:
        return random.choice(messages["pauses"]["bad"]), False

def getSpeechRateMessage(speechRate):
    speechRate = float(speechRate)
    if(speechRate >= SPEECHRATE_RANGE[0] and speechRate <= SPEECHRATE_RANGE[1]):
        return random.choice(messages["speechRate"]["good"]), True
    elif(speechRate < SPEECHRATE_RANGE[0]):
        return random.choice(messages["speechRate"]["low"]), False
    else:
        return random.choice(messages["speechRate"]["high"]), False

class ThreadWithReturnValue(Thread):
    def __init__(self, group=None, target=None, name=None,
                 args=(), kwargs={}, Verbose=None):
        Thread.__init__(self, group, target, name, args, kwargs)
        self._return = None
    def run(self):
        print(type(self._target))
        if self._target is not None:
            self._return = self._target(*self._args,
                                                **self._kwargs)
    def join(self, *args):
        Thread.join(self, *args)
        return self._return


def deleteIfExists(fileName):
    if(os.path.isfile(fileName+'.wav')):
        os.remove(fileName)
    if(os.path.isfile(fileName+'.TextGrid')):
        os.remove(fileName)

def callGoogle(filePath):
    # import pdb; pdb.set_trace()
    # f = open(credentialsPathSpeech,'r')
    # GOOGLE_CLOUD_SPEECH_CREDENTIALS = f.read()
    

    GOOGLE_CLOUD_SPEECH_CREDENTIALS = service_account.Credentials.from_service_account_file(credentialsPathSpeech)
    client = speech_v1p1beta1.SpeechClient(credentials = GOOGLE_CLOUD_SPEECH_CREDENTIALS)

    storage_client = storage.Client.from_service_account_json(credentialsPathStorage)
    buckets = list(storage_client.list_buckets())
    bucket_name = "bigtalkaudio"
    bucket = storage_client.get_bucket(bucket_name)
    if(bucket is None):
        bucket = storage_client.create_bucket(bucket_name)

    source_file_name = filePath
    destination_blob_name = filePath
    blob = bucket.blob(destination_blob_name)
    blob.upload_from_filename(source_file_name)
    blob.make_public()
    URL = blob.public_url

    URL = "gs://"+bucket_name+"/"+filePath

    boost = 8.0
    speech_contexts_element = {"phrases": fillerWords, "boost": boost}
    speech_contexts = [speech_contexts_element]

    sample_rate_hertz = 44100
    language_code = "en-US"
    encoding = enums.RecognitionConfig.AudioEncoding.MP3
    config = {
        "speech_contexts": speech_contexts,
        "sample_rate_hertz": sample_rate_hertz,
        "language_code": language_code,
        "encoding": encoding,
    }
    audio = {"uri": URL}

    try:
        operation = client.long_running_recognize(config, audio)
        response = operation.result()
    except Exception as e:
        raise e
    blob.delete()
    text = ""
    for result in response.results:
        alternative = result.alternatives[0]
        text += alternative.transcript
    result = {}
    words = text.split(' ')
    for word in fillerWords:
        result[word] = 0
    for word in words:
        if word in fillerWords:
            result[word] += 1
    result["text"] = text
    # print(result)
    return result


def getAudioDuration(p):
    f = sf.SoundFile(p+".wav")
    return(len(f) / f.samplerate)

def getLoudness(p):
    # import pdb; pdb.set_trace()
    data, rate = sf.read(p+".wav") 
    meter = pyln.Meter(rate) 
    return (meter.integrated_loudness(data))

def getResults(p,c, requestType):

    try:
        temp = mysp.mysptotal(p,c)
        result2 = []
        result = {}

        if(requestType == "realtime"):

            result["intonation"] = [temp["f0_std"]]
            result["loudness"] = [getLoudness(p)]
            result["clarity"] = [temp["articulation_rate"]]
            result["duration"] = [getAudioDuration(p)]
            result["loudness_message"], result["isLoudnessGood"] = getLoudnessMessage(result["loudness"][0])
            result["clarity_message"], result["isClarityGood"] = getClarityMessage(temp["articulation_rate"])
            result["intonation_message"], result["isIntonationGood"] = getIntonationMessage(temp["f0_std"])
            if(result["isLoudnessGood"] == False):
                result["message"] = "You are not audible"
            elif(result["isClarityGood"] == False):
                result["message"] = "You are mumbling"
            elif(result["isIntonationGood"] == False):
                result["message"] = random.choice(["Tone needs variation","Tone feels montonous"])
            else:
                result["message"] = "All okay!"
            return (result)

        if(requestType == "basic"):
            result2.append(temp["f0_std"])
            result2.append(getLoudness(p))
            result2.append(temp["articulation_rate"])
            result2.append(temp["number_of_pauses"])
            result2.append(math.ceil(int(temp["rate_of_speech"])*float(temp["original_duration"])*(60/float(temp["original_duration"]))/1.74))        

        if(requestType == "advanced"):
            result2.append(temp["f0_std"])
            result2.append(getLoudness(p))
            result2.append(temp["articulation_rate"])
            result2.append(temp["number_of_pauses"])
            result2.append(math.ceil(temp["rate_of_speech"]*float(temp["original_duration"])*(60/float(temp["original_duration"]))/1.74))
            # TODO call google API
        return (result2)

    except:
        raise ValueError("Audio was not clear")

        

def getResultRealTime(p,c):
    try:
        return (getResults(p,c,"realtime"))
    except:
        raise ValueError("Audio was not clear")

def getResultSlicedAudio(p,c):
    intonation = []
    loudness = []
    clarity = []
    pauses = []
    speechRate = []
    result = {}
    audioDuration = getAudioDuration(p)
    fullAudioFile = AudioSegment.from_wav(p+".wav")
    i=0
    # import pdb; pdb.set_trace()
    while(i < math.floor(audioDuration//30)):
        temp = fullAudioFile[i*30*1000:(i*30+30)*1000]
        temp.export(p+str(i)+'.wav', format = "wav")
        try:
            data = getResults(p+str(i),c,"basic")
            intonation.append(data[0])
            loudness.append(data[1])
            clarity.append(data[2])
            pauses.append(data[3])
            speechRate.append(data[4])
        except:
            intonation.append("NA")
            loudness.append("NA")
            clarity.append("NA")
            pauses.append("NA")
            speechRate.append("NA")
        i+=1
        deleteIfExists(p+str(i))
    if(i == 0):
        return {}
    remainingTime = math.floor(audioDuration%30)*1000
    if(remainingTime>=15*1000):
        temp = fullAudioFile[-remainingTime:]
        temp.export(p+str(i)+'.wav', format = "wav")
        try:
            data = getResults(p+str(i),c,"basic")
            intonation.append(data[0])
            loudness.append(data[1])
            clarity.append(data[2])
            pauses.append(data[3])
            speechRate.append(data[4])
        except:
            intonation.append("NA")
            loudness.append("NA")
            clarity.append("NA")
            pauses.append("NA")
            speechRate.append("NA")
    deleteIfExists(p+str(i))

    result["intonation"] = intonation
    result["loudness"] = loudness
    result["clarity"] = clarity
    result["pauses"] = pauses
    result["speechRate"] = speechRate

    return (result)
    

def getResultFullAudio(p,c):
    intonation = []
    loudness = []
    clarity = []
    pauses = []
    speechRate = []
    result = {}

    try:
        data = getResults(p,c,"basic")
        intonation.append(data[0])
        loudness.append(data[1])
        clarity.append(data[2])
        pauses.append(data[3])
        speechRate.append(data[4])
    except:
        raise ValueError("Audio was not clear")

    
    result["intonation"] = intonation
    result["loudness"] = loudness
    result["clarity"] = clarity
    result["pauses"] = pauses
    result["speechRate"] = speechRate
    result["duration"] = getAudioDuration(p)
    return(result)

def getResultBasic(p,c):
    try:
        t1 = ThreadWithReturnValue(target=getResultSlicedAudio, args=(p,c,))
        t2 = ThreadWithReturnValue(target=getResultFullAudio, args=(p,c,))
        t1.start()
        t2.start()
        temp1 = t1.join()
        temp2 = t2.join()
        temp1["full"] = temp2
        temp1["clarity_message"],temp1["isClarityGood"] = getClarityMessage(temp2["clarity"][0])
        temp1["loudness_message"],temp1["isLoudnessGood"] = getLoudnessMessage(temp2["loudness"][0])
        temp1["intonation_message"],temp1["isIntonationGood"] = getIntonationMessage(temp2["intonation"][0])
        temp1["pauses_message"],temp1["isPausesGood"] = getPausesMessage(temp2["pauses"][0], round(temp2["duration"]/60))
        temp1["speechRate_message"],temp1["isSpeechRateGood"] = getSpeechRateMessage(temp2["speechRate"][0])
        return temp1
    except:
        raise ValueError("Audio was not clear")
    

def getResultAdvanced(p,c):
    dictionary = {}
    for word in fillerWords:
        dictionary[word] = 0
    dictionary["text"] = ""
    try:
        data = callGoogle(p+'.wav')
    except Exception as e:
        raise e
    count = 0
    for word in fillerWords:
        dictionary[word] += data[word]
        count+=data[word]
    dictionary["text"] += data["text"]
    dictionary["duration"] = getAudioDuration(p)
    dictionary["fillerWords_message"],dictionary["isFillerWordsGood"] = getPausesMessage(count, round(dictionary["duration"]/60))
    # print(dictionary)
    return dictionary


    



   

